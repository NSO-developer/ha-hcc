An NSO Tail-f HA HCC Layer-2 Deployment Example
===============================================

This example is a demo implementation of the setup described by the NSO
Administration Guide chapter NSO Deployment.
The example shows the parts that describe the installation of NSO, initial
configuration of NSO, upgrade of NSO, and upgrade of NSO packages on the paris
and london nodes.

While this example uses containers, it is not intended as a guide to running
NSO in Docker. See "NSO in Docker for development and production" for
guidance: https://gitlab.com/nso-developer/nso-docker

Example Network Overview
~~~~~~~~~~~~~~~~~~~~~~~~
manager: management station with CLI, RESTCONF, and SSH access to the london
         and paris nodes.
paris:   NSO, Tail-f HCC package (uses arping and iproute2 utils)
london:  NSO, Tail-f HCC package (uses arping and iproute2 utils)


  ----------  docker 0 default bridge  ----------
                          |
                          | .1
  -----------  ParisLondonNet bridge  -----------
        |                 |                |
        |                 |                |
                    192.168.23.0/16
        |                 |                |
        | .98             | .2             | .99
   +----------+     +----------+     +----------+
   |  london  |     | manager  |     |  paris   |
   +----------+     +----------+     +----------+

Prerequisites
~~~~~~~~~~~~~
- NSO_VERSION >= 5.8
- nso-${NSO_VERSION}.linux.x86_64.installer.bin x 2, e.g. for NSO 5.8 and 5.8.1
- ncs-${NSO_VERSION}-tailf-hcc-${TAILF_HCC_VERSION}.tar.gz x 2, e.g 5.8 and 5.8.1
    Example:
    $ pwd
    /Users/tailf/upgrade-l2
    $ ls -1 n*
    ncs-5.8-tailf-hcc-5.0.3.tar.gz
    ncs-5.8.1-tailf-hcc-5.0.3.tar.gz
    nso-5.8.1.linux.x86_64.installer.bin
    nso-5.8.linux.x86_64.installer.bin
- Docker installed

Running the Example
~~~~~~~~~~~~~~~~~~~
1. Add the NSO installation and Tail-f HCC packages into the directory of this
   README. Change the version number NSO_VERSION and TAILF_HCC_VERSION
   variables in the setup.sh file.
2. Run the setup.sh script:
    $ ./setup.sh # will follow the manager node output after setup
   In another terminal window:
    $ docker ps # to make sure the paris, london, and manager containers are up
3. Examine the manager node output:
   The demo is divided into a CLI scripting part by the app/run.sh script and a
   RESTCONF Python script part in app/run_rc.py. The two scripts will run the
   same demo and will execute the following steps on the paris and
   london nodes:
   a. Reset, set up, start the paris and london nodes, and enable HA assuming
      start-up settings. The initial VIP node is the paris node.
   b. Add some dummy config to the paris node, replicated to secondary node 2.
   c. Disable HA on the secondary node london to simulate secondary node
      failure, primary paris will assume role none as all secondary nodes
      disconnected (see alarm), set paris back to primary and enable the
      secondary again to re-connect to the primary node.
   d. Disable HA on the primary paris to make london failover to primary role.
      VIP node becomes the london node.
   e. Enable HA on the paris node that will now assume secondary role.
   f. Role-revert the nodes back to start-up settings. VIP go back to the paris
      node.
   g. Upgrade from NSO OLD_VERSION to NEW_VERSION.
   h. Backup both nodes before upgrading NSO.
   i. scp and install the NSO and HCC package NEW_VERSION on both nodes.
   j. Rebuild the primary paris node packages in its package store for NSO
      NEW_VERSION.
   k. Replace the currently installed packages on the paris node with the ones
      built for NSO NEW_VERSION.
   l. Disable primary node paris high availability for secondary node london to
      automatically failover and assume primary role in read-only mode.
   m. Upgrade the paris node to NSO NEW_VERSION
   n. Disable high availability for the london node.
   o. Enable high availability for the paris node that will assume primary role.
   p. Rebuild the secondary london node packages in its package store for NSO
      NEW_VERSION.
   q. Replace the currently installed packages on the london node with the ones
      built for NSO NEW_VERSION.
   r. Upgrade the london node to NSO NEW_VERSION.
   s. Enable high availability for the london node that will assume secondary
      role.
   t. Upgrade primary paris node packages and sync the packages to the secondary
      london node.
   u. Add some new config through the primary paris node.
   v. Done!
   x. Follow the developer log.
4. Connect to the NSO CLI on the current primary node VIP through the
   management station:
    $ docker exec -it manager bash
    root@manager:/manager$ ssh -l admin -p 2024 192.168.23.122 # Connect to
     the primary NSO node CLI using the VIP address.
    admin@ncs# show high-availability status
    admin@ncs# exit
5. Get the high-availability status using RESTCONF instead of CLI:
    $ docker exec -it manager bash
   Get a RESTCONF token for authentication using the CLI:
    root@manager$ ssh -l admin -p 2024 192.168.23.122
    admin@nso-paris# generate_token
    token N6jNpjth1FHyNNy0s/VeSNGSMlhQVN5cnINPwbtrAik=
    admin@nso-paris# exit
   Now use curl or Python requests, as the run_rc.py script does, to get
   the HA status. curl variant:
    root@manager$ curl -ki -H "X-Auth-Token: \
    N6jNpjth1FHyNNy0s/VeSNGSMlhQVN5cnINPwbtrAik=" \
    -H "Accept: application/yang-data+json" \
    https://192.168.23.122:8888/restconf/data/\
    tailf-ncs:high-availability/status
    {
      "tailf-ncs:status": {
        "mode": "master",
        "current-id": "paris",
        "assigned-role": "master",
        "read-only-mode": false,
        "connected-slave": [
          {
            "id": "london",
            "address": "192.168.23.98"
          }
        ]
      }
    }
   Python requests variant:
    root@manager$ python3
    >>> import requests
    >>> requests.packages.urllib3.disable_warnings(\
        requests.packages.urllib3.exceptions.InsecureRequestWarning)
    >>> r = requests.get("https://192.168.23.122:8888/restconf/data/\
        tailf-ncs:high-availability/status", \
        headers={'Content-Type': 'application/yang-data+json', \
        'X-Auth-Token': 'N6jNpjth1FHyNNy0s/VeSNGSMlhQVN5cnINPwbtrAik='}, \
        verify=False)
    >>> print(r.text)
    {
      "tailf-ncs:status": {
        "mode": "master",
        "current-id": "paris",
        "assigned-role": "master",
        "read-only-mode": false,
        "connected-slave": [
          {
            "id": "london",
            "address": "192.168.23.98"
          }
        ]
      }
    }
6. Connect to the london and paris shell to examine the Linux
   kernel route status.
     $ docker exec -it paris bash
     admin@paris:~/app$ ip address show dev eth0
     admin@paris:~/app$ arp -a
     admin@paris:~/app$ exit
7. Examine the setup.sh -> Dockerfile -> app/run.sh -> app/Makefile ->
   Dockerfile.manager -> app/run.sh .> app/run_rc.py files in that order.
8. Cleanup
     $ docker stop paris london manager
     $ docker network rm ParisLondonNet

Implementation Details
~~~~~~~~~~~~~~~~~~~~~~
This demo uses Docker containers to set up the Tail-f HCC NSO package in layer 2
mode with NSO and its dependencies and perform an NSO version upgrade and
package version upgrade as described in the NSO Administration Guide chapter
NSO Deployment. The steps for the paris and london nodes described by the
documentation are implemented by the setup.sh, Dockerfile, app/run.sh,
app/run_rc.py, and Makefile files.

NSO is installed by and started in the context of an "admin" user that belongs
to the "ncsadmin" user group. sudo is installed as the Tail-f HCC
implementation requires sudo when running the "ip" command in a non-root
context. Linux capabilities such as network admin are added to containers and
specific commands to allow running them in the context of the admin user. See
the "docker run" command in the setup.sh file and the Dockerfile for details.

SSH to the paris and london nodes for shell and NSO CLI accces use public
key-based authentication/login, while RESTCONF uses token validation for
authentication. Tokens are retrieved through the NSO CLI that uses a
shell script to generate a token. Password authentication has been disabled for
the paris and london nodes.

Further Reading
~~~~~~~~~~~~~~~
+ NSO Administrator Guide: NSO Deployment, NSO built-in HA, and Tail-f HCC
  Package
+ examples.ncs/development-guide/high-availability examples
+ https://github.com/ThomasHabets/arping
+ https://wiki.linuxfoundation.org/networking/iproute2
+ https://docs.docker.com/engine/reference/run/
